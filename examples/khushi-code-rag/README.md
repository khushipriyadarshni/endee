Project: AI Codebase Intelligence using Endee as the vector database.

**Location** in forked Endee repo: `examples/khushi-code-rag`

---

## Overview

This project implements a **Retrieval-Augmented Generation (RAG)** system for **semantic understanding of source code**, using **Endee as the core vector database**.

The system indexes a GitHub repository’s source code into Endee and enables users to ask **natural-language questions** about the codebase. Answers are generated by an LLM using only the most relevant code context retrieved through vector similarity search.

The project is implemented directly inside a **fork of the Endee repository**, demonstrating a real-world AI/ML application where **vector search is the primary component**.

---

## Problem Statement

Understanding large codebases is time-consuming and inefficient.

Developers often need to:
- Find where a feature is implemented
- Understand unfamiliar functions or modules
- Trace configuration, database, or business logic

Traditional keyword-based search fails because it cannot capture **semantic meaning**.  
A system is required that combines **semantic vector search** with **LLM-based reasoning**.

---

## Solution

This project provides a complete **RAG pipeline for code intelligence**:

- Clone a GitHub repository
- Extract source code files (`.py`, `.js`, `.java`)
- Chunk code into semantically meaningful segments
- Generate embeddings using OpenAI
- Store embeddings in **Endee vector database**
- Retrieve relevant code chunks using vector similarity search
- Generate grounded answers using an LLM

Endee enables fast and accurate **semantic retrieval**, which is the foundation of the system.

---

## Architecture

- `ingest.py`: clones the repo, extracts files, chunks them, and stores into Endee via `endee_store.py`.
- `endee_store.py`: wrapper that uses Endee REST APIs when configured, otherwise persists an in-memory store under `repo/endee_local_store.json`. Embeddings are generated via OpenAI.
- `query.py`: retrieves top-3 chunks and builds a prompt for OpenAI Chat Completion.
- `app.py`: Streamlit UI to index a repo and ask questions.

Vector similarity search in Endee is the core mechanism enabling
context retrieval for the RAG pipeline.

---

### Pipeline Flow

```
GitHub Repository
        ↓
Code Extraction & Chunking
        ↓
Embedding Generation (OpenAI)
        ↓
Endee Vector Database (Upsert)
        ↓
Vector Similarity Search (Query)
        ↓
Retrieved Context + User Question
        ↓
LLM Response (RAG)
```
---

## Practical Use Case

This project demonstrates a RAG (Retrieval Augmented Generation) workflow for:
- Semantic search over code
- AI-assisted code understanding
- Repository Q&A
- Vector search is the core component of this system.

---

## Endee Integration

This project uses **Endee as the primary vector database**.

---

## How Endee is used

Set the following environment variables:

```
ENDEE_URL=<your endee endpoint>
ENDEE_API_KEY=<your api key>
```

The system interacts with Endee via REST APIs:

- `POST /vectors/upsert` — store embeddings
- `POST /vectors/query` — perform similarity search

A local store is used **only as a fallback** when Endee is unavailable, ensuring Endee remains the main vector backend.

---

## Setup & Run

1. Create and activate a Python virtual environment.
2. Install dependencies:

```bash
pip install -r requirements.txt
```

3. Set environment variables:

```bash
OPENAI_API_KEY=sk-...
ENDEE_URL=https://your-endee-instance
ENDEE_API_KEY=...
```

4. Run the application:

```bash
streamlit run app.py
```

5. Open in browser:

```
http://localhost:8501
```

6. Provide a GitHub repository URL, index it, and start asking questions about the codebase.

---

## Example queries

- "How does authentication work in this repo?"
- "Where is the database connection initialized?"
- "What's the purpose of function X in file Y?"

---

## Evaluation Checklist

- [x] Forked Endee repository
- [x] Uses Endee as vector database
- [x] Demonstrates RAG (Retrieval-Augmented Generation)
- [x] Vector search is core to the system
- [x] Complete project hosted on GitHub
